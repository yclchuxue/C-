## C++总结

### new 和 alloc 的区别
1.new是C++关键字，需要编译器支持；malloc是库函数，需要头文件支持。

2.使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。而malloc则需要显式地指出所需内存的尺寸。

3.new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全性的操作符。而malloc内存分配成功则是返回void * ，需要通过强制类型转换将void*指针转换成我们需要的类型。

4.new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。而malloc是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作。

5.C++允许自定义operator new 和 operator delete 函数控制动态内存的分配[链接](https://blog.csdn.net/jiemashizhen/article/details/125922798)。

6.new做两件事，分别是分配内存和调用类的构造函数，而malloc只是分配和释放内存。new操作符从自由存储区上为对象动态分配内存空间，而malloc函数从堆上动态分配内存。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。自由存储区不等于堆，如上所述，布局new就可以不位于堆中。

7.new内存分配失败时，会抛出bac_alloc异常。malloc分配内存失败时返回NULL。

8.内存泄漏对于new和malloc都能检测出来，而new可以指明是哪个文件的哪一行，malloc不可以。

#### new_handler

当operator new申请一个内存失败的时候，它会进行如下的处理步骤：
    1、如果存在客户指定的处理函数，则调用处理函数（new_handler），如果不存在则抛出一个异常。

    2、继续申请内存分配请求。
    3、判断申请内存是否成功，如果成功则返回内存指针，如果失败转向处理步骤1

为了自定义这个“用以处理内存不足”的函数new_handler，用户可以调用set_new_handler进行设置[链接](https://www.cnblogs.com/ljygoodgoodstudydaydayup/p/4209879.html)

#### placement new

placement new：只是operator new重载的一个版本。它并不分配内存，只是返回指向已经分配好的某段内存的一个指针。因此不能删除它，但需要调用对象的析构函数。

如果你想在已经分配的内存中创建一个对象，使用new时行不通的。也就是说placement new允许你在一个已经分配好的内存中（栈或者堆中）构造一个新的对象。原型中void* p实际上就是指向一个已经分配好的内存缓冲区的的首地址。[链接](https://www.cnblogs.com/luxiaoxun/archive/2012/08/10/2631812.html)

### 堆、栈、数据段、代码段

[链接](https://blog.csdn.net/chen1083376511/article/details/54930191)

### 加static是否是线程安全的

1 全局变量、文件域的static变量和类的static成员变量在main函数执行之前初始化
2 局部静态变量在第一次被使用时初始化
3 非局部静态变量是线程安全的
4 局部静态变量在C++11后也是线程安全的

[链接](https://blog.csdn.net/leigelaile1/article/details/121492055)

### 线程池

创建一定的线程，和一个任务队列，线程循环从队列中获取任务进行处理，线程池可以减少创建和销毁进程的消耗；[链接](https://zhuanlan.zhihu.com/p/560291125)

#### 线程同步

线程同步的方式有：

* 互斥锁

优点： 使用简单；
缺点：重复锁定和解锁，每次都会检查共享数据结构，浪费时间和资源；繁忙查询的效率非常低；

* 条件变量

* 读写锁

读写锁 也称之为 共享-独占锁，一般用在读和写的次数有很大不同的场合。即对某些资源的访问会出现两种情况，一种是访问的排他性，需要独占，称之为写操作；还有就是访问可以共享，称之为读操作。

* 信号量

[链接](https://www.cnblogs.com/sherlock-lin/p/14538083.html)

### 多线程和多进程的选择与区别

数据共享、同步
    多进程:数据共享复杂，需要用IPC；数据是分开的，同步简单

    多线程:因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂

内存、CPU
    多进程:占用内存多，切换复杂，CPU利用率低

    多线程:占用内存少，切换简单，CPU利用率高

创建销毁、切换
    多进程:创建销毁、切换复杂，速度慢

    多线程:创建销毁、切换简单，速度很快

编程、调试
    多进程:编程简单，调试简单

    多线程:编程复杂，调试复杂

可靠性
    多进程:进程间不会互相影响

    多线程:一个线程挂掉将导致整个进程挂掉

分布式
    多进程:适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单

    多线程:适应于多核分布式

* 需要频繁创建销毁的优先用线程

* 需要进行大量计算的优先使用线程

* 强相关的处理用线程，弱相关的处理用进程

* 可能要扩展到多机分布的用进程，多核分布的用线程

* 都满足需求的情况下，用你最熟悉、最拿手的方式

[链接](https://blog.csdn.net/lishenglong666/article/details/8557215)

### 进程间通信，分别使用的场景

#### 管道

匿名管道，用完就销毁。命名管道也被叫做 FIFO，因为数据的传输方式是先进先出（first in first out）。管道传输数据是单向的，如果想相互通信，需要创建两个管道才行。

　　缺点：管道的通信方式效率低，不适合进程间频繁地交换数据。

　　优点：简单。

#### 消息队列

缺点：

* 通信不及时
* 不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。
　　
优点：

* 可以频繁地交换数据
* 可以自定义数据类型

#### 共享内存

消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。而共享内存就很好的解决了这一问题。

现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。

共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到，大大提高了进程间通信的速度。

#### 信号量

用了共享内存通信方式，带来新的问题：如果多个进程同时修改同一个共享内存，很有可能发生冲突。例如两个进程都同时写一个地址，先写的进程会的内容会被覆盖。

为了防止多进程竞争共享资源而造成的数据错乱，需要一种保护机制，使得共享的资源在任意时刻只能被一个进程访问。信号量就实现了这一保护机制。

信号量本质是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。

#### 信号

上面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，需要用信号的方式来通知进程。

信号跟信号量虽然名字相似，但两者用途完全不一样，就好像 Java 和 JavaScript 的区别。

在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。可以通过 kill -l 命令查看所有的信号.

运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。

#### socket

网络通讯

[链接](https://www.cnblogs.com/zhuminghui/p/15405591.html)

### 内存泄露的处理

[内存泄漏](https://youle.zhipin.com/questions/b42775ee3cba80e3tnVz29m6FlQ~.html)：从堆上申请的内存在生命期结束不能交还给操作系统，导致程序私有内存增长的现象

预防:

1.使用智能指针管理内存或者内存池管理内存

2.使用面向对象的方式管理内存，构造申请析构释放

3.使用原生 malloc,free,new，delete 要配对，对于数组释放要使用 delete[]

排查泄露:

1.使用 cppcheck 检查静态内存是否泄露，避免大海捞针找没释放的地方

2.vld 可以查询动态内存泄露

3.其他工具比如 mfc 泄露检查等

4.[使用 mtrace 分析内存泄露](https://zhuanlan.zhihu.com/p/83547768)

### [智能指针的使用](https://blog.csdn.net/cpp_learner/article/details/118912592)

### [多态的概念和实现](https://blog.csdn.net/afei__/article/details/82142775)

[多重继承继续看看](https://blog.csdn.net/zaishuiyifangxym/article/details/88685518)

### 一个类一个虚函数表还是一个对象一个虚函数表

### [vector的原理](https://segmentfault.com/a/1190000040103598)

vector是一个动态数组，它维护了一段连续的动态内存空间，然后有三个成员变量分别保存开始位置、当前已使用位置、申请的动态内存的最后一个位置的下一个位置，每当当前所申请的动态内存已经使用完时，它按照原有空间大小双倍重新申请，并把原来的元素都拷贝过去。

* 访问元素，时间复杂度为O(1);
* 在末尾插入或者删除元素，时间复杂度也为O(1);
* 在中间插入或者删除元素，时间复杂度为O(n)。

vector使用时注意事项：

1、在不确定的情况下使用at而不是operator[]
* 在前面访问元素小节那里我们说了，at会检查是否越界，假设不确定当前访问动作是否会越界，那么我们应该使用at函数。

2、什么类型不可以作为vector的模板类型

* 对于vector模板特化类型，因为在vector的实现过程中，变量会经常被拷贝或者赋值，所以vector的模板类型应该具有公有的拷贝构造函数和重载的赋值操作符函数。

3、什么情况下vector的迭代器会失效
 
* 第一是在vector容器中间根据指定迭代器删除元素，也就是调用erase函数，此时因为当前位置会被后面的元素覆盖，所以该指定迭代器会失效，不过此时可以通过erase的返回值重新得到当前位置的正确迭代器；
* 第二是在vector需重新申请内存的时候，比如扩容，比如释放未使用的内存等等这些过程中都会发生迭代器失效的问题，因为内存有了变动，此时就需要重新获得迭代器；
* 有人说往vector中间插入数据也会使迭代器失效，实际上根据源码是不会的，看上面的insert实现可以得知，再插入完成以后给当前迭代器重新赋值了的。

### [vector与链表的区别](https://blog.51cto.com/u_15295315/3045408)

1）vector底层实现是数组；list是双向 链表。

2）vector支持随机访问，list不支持。

3）vector是顺序内存，list不是。

4）vector在中间节点进行插入删除会导致内存拷贝，list不会。

5）vector一次性分配好内存，不够时才进行2倍扩容；list每次插入新节点都会进行内存申请。

6）vector随机访问性能好，插入删除性能差；list随机访问性能差，插入删除性能好。


### [Top K 问题](https://juejin.cn/post/6844903774004183047)
在一堆数据里面找到前 K 大（当然也可以是前 K 小）的数。

* 快排

* 堆排

大数据多文件排序问题，考的很深 双路 多路 IOPS


### [敲下 www.baidu.com 以后发生的事情](https://blog.csdn.net/darkfaker/article/details/79842793)

从全局角度可总结为一下几点：
1、浏览器向DNS服务器查找输入URL对应的IP地址
2、DNS服务器返回网站的IP地址
3、浏览器根据IP地址与目标Web服务器在80端口上建立TCP 连接。
4、浏览器获取客户端请求页面的HTML代码。
5、浏览器在显示窗口渲染HTML文件，并进行界面控制显示
6、窗口关闭时，浏览器终止与服务器的连接

### [TCP与UDP的区别与应用](https://segmentfault.com/a/1190000021815671)

TCP有以下特点：

* TCP充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。
* 此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。
* 根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（ 主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现）。

UDP 常用于以下几个方面：

* 包总量较少的通信（DNS、SNMP等）；
* 视频、音频等多媒体通信（即时通信）；
* 限定于 LAN 等特定网络中的应用通信；
* 广播通信（广播、多播）。


用户数据报协议 UDP（User Datagram Protocol）：

* UDP 在传送数据之前不需要先建立连接，远程主机在收到 UDP 报文后，不需要给出任何确认。
* 虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： * QQ 语音、 QQ 视频 、直播等等

传输控制协议 TCP（Transmission Control Protocol）：

* TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。
* TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、流量控制、拥塞控制机制，在数据传完后，还会四次挥手断开连接用来节约系统资源），这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。
* TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

### [ TCP 三次握手和四次挥手](https://segmentfault.com/a/1190000039165592)

三次握手
* SYN：连接请求/接收 报文段
* seq：发送的第一个字节的序号
* ACK：确认报文段
* ack：确认号。希望收到的下一个数据的第一个字节的序号

1）第一次握手：客户端向服务端发送一个 SYN 报文（SYN = 1），并指明客户端的初始化序列号 ISN(x)，即图中的 seq = x，表示本报文段所发送的数据的第一个字节的序号。此时客户端处于 SYN_Send 状态。

* SYN-SENT ：在发送连接请求后等待匹配的连接请求

2）第二次握手：服务器收到客户端的 SYN 报文之后，会发送 SYN 报文作为应答（SYN = 1），并且指定自己的初始化序列号 ISN(y)，即图中的 seq = y。同时会把客户端的 ISN + 1 作为确认号 ack 的值，表示已经收到了客户端发来的的 SYN 报文，希望收到的下一个数据的第一个字节的序号是 x + 1，此时服务器处于 SYN_REVD 的状态。

* SYN-RECEIVED：在收到和发送一个连接请求后等待对连接请求的确认

3）第三次握手：客户端收到服务器端响应的 SYN 报文之后，会发送一个 ACK 报文，也是一样把服务器的 ISN + 1 作为 ack 的值，表示已经收到了服务端发来的的 SYN 报文，希望收到的下一个数据的第一个字节的序号是 y + 1，并指明此时客户端的序列号 seq = x + 1（初始为 seq = x，所以第二个报文段要 +1），此时客户端处于 Establised 状态。

服务器收到 ACK 报文之后，也处于 Establised 状态，至此，双方建立起了 TCP 连接。

* ESTABLISHED：代表一个打开的连接，数据可以传送给用户

为什么要三次握手
三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。

只有经过三次握手才能确认双发的收发功能都正常，缺一不可：

    第一次握手（客户端发送 SYN 报文给服务器，服务器接收该报文）：客户端什么都不能确认；服务器确认了对方发送正常，自己接收正常
    第二次握手（服务器响应 SYN 报文给客户端，客户端接收该报文）：
    客户端确认了：自己发送、接收正常，对方发送、接收正常；

    服务器确认了：对方发送正常，自己接收正常

    第三次握手（客户端发送 ACK 报文给服务器）：
    客户端确认了：自己发送、接收正常，对方发送、接收正常；

    服务器确认了：自己发送、接收正常，对方发送、接收正常

time_wait的状态和作用:等待足够的时间以确保远程TCP接收到连接中断请求的确认；


### [挥手一定是四次吗](https://www.zhihu.com/question/63264012)

因为TCP是全双工通信的，要保证客户端和服务器端都不再发送信息和接收信息。

### [Reactor与Proactor模式区别](https://www.zhihu.com/question/26943938)

[链接](https://www.zhihu.com/question/26943938)



#### [同步、异步、阻塞、非阻塞](https://www.zhihu.com/question/19732473)

同步和异步关注的是消息通信机制

* 同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。
* 异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。

阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.

* 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。
* 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。

### [select，poll，epoll的作用原理](https://blog.csdn.net/jiejiemcu/article/details/107083724)

#### select
```
int select(int maxfdp1,fd_set *readset,fd_set *writeset,fd_set *exceptset,const struct timeval *timeout)

```
* maxfdp1指定感兴趣的socket描述符个数，它的值是套接字最大socket描述符加1，socket描述符0、1、2 … maxfdp1-1均将被设置为感兴趣（即会查看他们是否可读、可写）。

* readset：指定这个socket描述符是可读的时候才返回。

* writeset：指定这个socket描述符是可写的时候才返回。

* exceptset：指定这个socket描述符是异常条件时候才返回。

* timeout：指定了超时的时间，当超时了也会返回。

如果对某一个的条件不感兴趣，就可以把它设为空指针。

返回值：就绪socket描述符的数目，超时返回0，出错返回-1。

#### poll

poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，poll不限制socket描述符的个数，因为它是使用链表维护这些socket描述符的，其他的都差不多和select()函数一样，poll()函数返回后，需要轮询pollfd来获取就绪的描述符，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。
```
int poll (struct pollfd *fds, unsigned int nfds, int timeout);
```
#### epoll
其实相对于select和poll来说，epoll更加灵活，但是核心的原理都是当socket描述符就绪（可读、可写、出现异常），就会通知应用进程，告诉他哪个socket描述符就绪，只是通知处理的方式不同而已。

epoll使用一个epfd（epoll文件描述符）管理多个socket描述符，epoll不限制socket描述符的个数，将用户空间的socket描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。当epoll记录的socket产生就绪的时候，epoll会通过callback的方式来激活这个fd，这样子在epoll_wait便可以收到通知，告知应用层哪个socket就绪了，这种通知的方式是可以直接得到那个socket就绪的，因此相比于select和poll，它不需要遍历socket列表，时间复杂度是O(1)，不会因为记录的socket增多而导致开销变大。

epoll对socket描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：

* LT模式：即水平出发模式，当epoll_wait检测到socket描述符处于就绪时就通知应用程序，应用程序可以不立即处理它。下次调用epoll_wait时，还会再次产生通知。

* ET模式：即边缘触发模式，当epoll_wait检测到socket描述符处于就绪时就通知应用程序，应用程序必须立即处理它。如果不处理，下次调用epoll_wait时，不会再次产生通知。

ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。
 
epoll为什么更高效
1.当我们调用epoll_wait()函数返回的不是实际的描述符，而是一个代表就绪描述符数量的值，这个时候需要去epoll指定的一个数组中依次取得相应数量的socket描述符即可，而不需要遍历扫描所有的socket描述符，因此这里的时间复杂度是O(1)。

2.此外还使用了内存映射（mmap）技术，这样便彻底省掉了这些socket描述符在系统调用时拷贝的开销（因为从用户空间到内核空间需要拷贝操作）。mmap将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址（不管是用户空间还是内核空间都是虚拟地址，最终要通过地址映射映射到物理地址），使得这块物理内存对内核和对用户均可见，减少用户态和内核态之间的数据交换，不需要依赖拷贝，这样子内核可以直接看到epoll监听的socket描述符，效率极高。

3.另一个本质的改进在于epoll采用基于事件的就绪通知方式。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的socket描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个socket描述符，一旦检测到epoll管理的socket描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个socket描述符，当进程调用epoll_wait()时便可以得到通知，也就是说epoll最大的优点就在于它只管就绪的socket描述符，而跟socket描述符的总数无关。
 
### 网络传输中的滑动窗口

滑动窗口有发送窗口和接收窗口，由于接收速度和内存的限制，发送速度和接收速度不一致，若发送速度过快会导致丢包现象，所以发送窗口和接收窗口会协调大小，通过慢启动的方式来沟通双方的窗口大小，一般窗口大小以2倍的速度增大，出现丢包现象后就会减小。

### [长短连接](https://developer.aliyun.com/article/37987)

所谓长连接，指在一个TCP连接上可以连续发送多个数据包，在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维持。 

短连接是指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接，一般银行都使用短连接。 

比如http的，只是连接、请求、关闭，过程时间较短,服务器若是一段时间内没有收到请求即可关闭连接。

其实长连接是相对于通常的短连接而说的，也就是长时间保持客户端与服务端的连接状态。

通常的短连接操作步骤是： 
* 连接→数据传输→关闭连接；

而长连接通常就是： 
* 连接→数据传输→保持连接(心跳)→数据传输→保持连接(心跳)→……→关闭连接； 

这就要求长连接在没有数据通信时，定时发送数据包(心跳)，以维持连接状态，短连接在没有数据传输时直接关闭就行了。

### RPC的使用场景

当我们的应用访问量增加和业务增加时，发现单机已无法承受，此时可以根据不同的业务（划分清楚业务逻辑）拆分成几个互不关联的应用，分别部署在不同的机器上，此时可能也不需要用到 RPC 。

随着我们的业务越来越多，应用也越来越多，应用与应用相互关联调用，发现有些功能已经不能简单划分开，此时可能就需要用到 RPC。

比如，我们开发电商系统，需要拆分出用户服务、商品服务、优惠券服务、支付服务、订单服务、物流服务、售后服务等等，这些服务之间都相互调用，这时内部调用最好使用 RPC ，同时每个服务都可以独立部署，独立上线。

也就说当我们的项目太大，需要解耦服务，扩展性强、部署灵活，这时就要用到 RPC ，主要解决了分布式系统中，服务与服务之间的调用问题。

### [http2 和http1.1 区别](https://www.jianshu.com/p/63fe1bf5d445)

### [什么是协程？](https://www.cnblogs.com/liang1101/p/7285955.html)

协程就是轻量级线程，协程(用户级线程)是对内核透明的，也就是系统并不知道有协程的存在，是完全由用户自己的程序进行调度的，因为是由用户程序自己控制，那么就很难像抢占式调度那样做到强制的 CPU 控制权切换到其他进程/线程，通常只能进行 协作式调度，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到。

本质上，goroutine 就是协程。 不同的是，Golang 在 runtime、系统调用等多方面对 goroutine 调度进行了封装和处理，当遇到长时间执行或者进行系统调用时，会主动把当前 goroutine 的CPU (P) 转让出去，让其他 goroutine 能被调度并执行，也就是 Golang 从语言层面支持了协程。Golang 的一大特色就是从语言层面原生支持协程，在函数或者方法前面加 go关键字就可创建一个协程。

其他方面的比较

　　1. 内存消耗方面

　　　　每个 goroutine (协程) 默认占用内存远比 Java 、C 的线程少。
　　　　goroutine：2KB 
　　　　线程：8MB

　　2. 线程和 goroutine 切换调度开销方面

　　　　线程/goroutine 切换开销方面，goroutine 远比线程小
　　　　线程：涉及模式切换(从用户态切换到内核态)、16个寄存器、PC、SP...等寄存器的刷新等。
　　　　goroutine：只有三个寄存器的值修改 - PC / SP / DX.

### 用户态、内核态

### [不同语言的性能为什么不同？](https://www.zhihu.com/question/56693514)

1.优化程序
    编译器翻译成的二进制代码肯定会有不同，有些注重编译效率，有些注重运行效率，但是我觉得这一层面的效率差异以目前的cpu效率来说应该不是影响效率的主要因素，更多的是不同编程语言为了程序员方便或专注于解决某一类问题而增加的层层便利包装（wrapper），比如解释型语言（如js等）运行时需要先用解释器解释一次，这就多了一次“包装”，还比如java、c#等语言是编译为中间代码，也是类似解释器的一次包装，第一次运行也需要真正编译为机器代码，再者他们为了方便程序员，还增加了垃圾收集器，这样势必需要更多cpu时间来回收垃圾等，又会导致表现出来“更慢”一些，还有比如c++为了支持面向对象的继承、多态等，需要在内存中引入vtable机制，这样势必使用更多内存和cpu运行堆栈跳转，理论上也增加了cpu的指令数跳转数。

2.语言特性
    比如js最初用于web应用编程，它不会考虑严格的数据类型（势必要通过编译或运行时去猜）和直接访问底层内存，而c/c++可以更容易访问底层硬件，所以性能上会有一些差异，同时一些第三方支撑包比如directx目前还没有直接面向js的接口，那么调用他们势必需要通过操作系统或第三方厂商包装的代理程序(proxy)，所以速度也会受影响。

### [编译流程](https://www.cnblogs.com/Lynn-Zhang/p/5377024.html)

预处理--->编译--->汇编--->链接

### [学c++的经常会遇到 core down, 你怎么定位的](https://blog.csdn.net/hello2mao/article/details/79258471)

###  [string 内存布局](https://zhuanlan.zhihu.com/p/510507837)

string 首先会在栈中分配24字节的空间，能够存储22字节的字符，剩下两个字节用于存储string的大小，当string超过22字节时，将在堆空间的分配内存存储string，同时栈空间中的24字节的前8字节用于存储string所在的地址，中间8字节用于存储字符串的长度，后8字节存储空间分配大小。

### [c++内存布局](https://zhuanlan.zhihu.com/p/184957568)

### 一个目录下有很多文件，子目录，我现在向找出最大的100个文件然后删除它？怎样实现？

[链接](https://linux.cn/article-9495-1.html)

### [什么情况下会导致Rst？](https://www.cnblogs.com/yurang/p/11980464.html)

RST：当 RST = 1 时，表明 TCP 连接中出现了严重错误（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立传输连接。

一般情况下导致TCP发送RST报文的原因有如下3种：

1、SYN数据段指定的目的端口处没有接收进程在等待。

2、TCP想放弃一个已经存在的连接。

3、TCP接收到一个数据段，但是这个数据段所标识的连接不存在。

### unkonwhost 的原因？

### [tcp连接超时的原因](https://www.jianshu.com/p/d5060b16650e)

先无论是哪种语言，不管是客户端还是服务端，在 TCP 编程中通常都可以为 sock 设置一个 timeout 时间。而这个 timeout 又可以细分为 connect timeout、read timeout、write timeout。read timeout 和 write timeout 必须是在 connect 之后才能发生，今天不做过多讨论。上面那两种 timeout 均属于 connect timeout。

另外我们需要补充下 TCP 重传机制的相关知识：

我们知道在 TCP 的三次握手中，Client 发送 SYN，Server 收到之后回 SYN_ACK，接着 Client 再回 ACK，这时 Client 便完成了 connect() 调用，进入 ESTAB 状态。如果 Client 发送 SYN 之后，由于网络原因或者其他问题没有收到 Server 的 SYN_ACK，那么这时 Client 便会重传 SYN。重传的次数由内核参数 net.ipv4.tcp_syn_retries 控制，重传的间隔为 [1,3,7,15,31]s 等

如果 Client 重传完所有 SYN 之后依然没有收到 SYN_ACK，那么这时 connect() 调用便会抛出 connection timeout 错误。如果 Client 在重传 SYN 期间，Client 的 sock timeout 时间到了，那么这时 connect() 会抛出 timeout 错误。

### 谈谈Cgroup的理解

### bbr 拥塞控制算法

### [sendfile 的实现](https://www.jianshu.com/p/028cf0008ca5)

read/write 拷贝次数：

硬盘—>内核buf—>用户buf—>socket相关缓冲区—>协议引擎 

运行流程如下： 
1、sendfile系统调用，文件数据被copy至内核缓冲区 
2、再从内核缓冲区copy至内核中socket相关的缓冲区 
3、最后再socket相关的缓冲区copy到协议引擎 

相较传统read/write方式，2.1版本内核引进的sendfile已经减少了内核缓冲区到user缓冲区，再由user缓冲区到socket相关缓冲区的文件copy，而在内核版本2.4之后，文件描述符结果被改变，sendfile实现了更简单的方式，系统调用方式仍然一样，细节与2.1版本的不同之处在于，当文件数据被复制到内核缓冲区时，不再将所有数据copy到socket相关的缓冲区，而是仅仅将记录数据位置和长度相关的数据保存到socket相关的缓存，而实际数据将由DMA模块直接发送到协议引擎，再次减少了一次copy操作。 


### [了解server mesh吗](https://zhuanlan.zhihu.com/p/61901608)

服务网格是一个基础设施层，用于处理服务间通信。云原生应用有着复杂的服务拓扑，服务网格保证请求在这些拓扑中可靠地穿梭。在实际应用当中，服务网格通常是由一系列轻量级的网络代理组成的，它们与应用程序部署在一起，但对应用程序透明。（使用多种产品简单构建起一个服务架构，使服务更简单，例如将负载均衡、流量控制、分布式等模块直接采用已有产品）

Service Mesh具有如下优点：

* 屏蔽分布式系统通信的复杂性(负载均衡、服务发现、认证授权、监控追踪、流量控制等等)，服务只用关注业务逻辑；
* 真正的语言无关，服务可以用任何语言编写，只需和Service Mesh通信即可；
* 对应用透明，Service Mesh组件可以单独升级；

Service Mesh目前也面临一些挑战：

* Service Mesh组件以代理模式计算并转发请求，一定程度上会降低通信系统性能，并增加系统资源开销；
* Service Mesh组件接管了网络流量，因此服务的整体稳定性依赖于Service Mesh，同时额外引入的大量Service Mesh服务实例的运维和管理也是一个挑战；

### [讲讲 awk 命令](https://www.ruanyifeng.com/blog/2018/11/awk.html)

### 如何处理CPU负载过高的进程

### 局部变量有三个 A,B,C，那它的析构顺序

单独一个类， 这个类的成员函数编译后的代码会产生几份? 
聊聊你对异常的理解？ 
函数中，传递异常的时候通编译器会做什么事情？   函数退出的时候会做什么事情? 

### 函数是如何感知自己被调用了? (好像要答出*this 指针)

### [左值引用和右值引用](https://zhuanlan.zhihu.com/p/88047800)

左值引用要求右边的值必须能够取地址，如果无法取地址，可以用常引用；但使用常引用后，我们只能通过引用来读取数据，无法去修改数据，因为其被const修饰成常量引用了。

右值引用：不能取地址的，没有名字的，临时的就是右值；

在C++11中可以取地址的、有名字的就是左值，反之，不能取地址的、没有名字的就是右值（将亡值或纯右值）。

为什么要右值引用，右值引用在你需要使用寄存器中的值的时候可以进行右值引用。寄存器的刷新速度很快，没有右值引用的话就需要将寄存器中的值拷贝到内存中，在进行使用，这是很浪费时间的。

### 内存池如何实现

利用默认的内存管理函数new/delete或malloc/free在堆上分配和释放内存会有一些额外的开销。

通过分配一大块内存空间，由进程或线程自己来进行分配使用，减少了malloc/free的开销，可以提高性能，并减小内存碎片。

### [你了解哪些一致性](https://www.jianshu.com/p/f64d56d46911)

#### 最终一致性

#### 外部一致性

#### 会话一致性

#### 顺序一致性

#### 线性一致性

### 为什么有了LT(水平触发)还要有ET(边缘触发)

### 条件变量的实现原理

### 条件变量的wait为什么要用while保护

### namespace原理

### 

### 优先队列(priority_queue)
https://blog.csdn.net/weixin_36888577/article/details/79937886
* top 访问队头元素
* empty 队列是否为空
* size 返回队列内元素个数
* push 插入元素到队尾 (并排序)
* emplace 原地构造一个元素并插入队列
* pop 弹出队头元素
* swap 交换内容

升序队列:
```
//对于基础类型 默认是大顶堆

priority_queue<int> a; 

priority_queue <int,vector<int>,greater<int> > q;
```
降序队列
```
//这样就是小顶堆

priority_queue <int,vector<int>,less<int> >q;
```
题目练习:合并K个升序链表